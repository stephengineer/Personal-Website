# 简历

## 教育背景

佐治亚理工学院(美国，佐治亚)
计算机科学(硕士)
2014-09 ~ 2016-06

加州大学洛杉矶分校(美国，洛杉矶)
数学(学士)
2010-09 ~ 2014-06

## 工作经验

---
海纳AI(中国，北京)
NLP算法负责人
2024-03 ~ 至今

离职原因：公司资金链断裂，无法支付员工薪资
实线团队：3人

### AI面试官

- 跟随[InstructGPT](https://arxiv.org/abs/2203.02155)论文中数据类别、数量、长度分布利用私有数据源、Python爬虫技术，self-instruct方式，成功构建了高效、自动化的训练和测试数据pipeline生成了万条SFT数据。
- 采用LoRA和QLoRA技术对ChatGLM3/4、LLaMA2/3、Qwen、InternLM等不同规模（6B-32B参数）的开源大模型进行SFT，确保模型输出的稳定性与一致性。
- 通过PPO、DPO和RLHF等先进算法对模型输出进行了细致的对齐和优化，以适应面试领域的特定需求，实现了模型在面试领域的SOTA性能。
- 利用Embedding对比相关性改进了few-shot学习方式提升了小样本学习场景下的模型性能，结合COT方法提出causal inference策略增强了模型对复杂问题解决的推理能力。
- 通过对比四种不同的模型优化方案，进行了细致的微调实验，最终实现了模型准确率的显著提升
- 应用FastLLM、vLLM、llama.cpp、TensorRT等模型推理加速框架，结合Triton服务部署，显著提高了模型的吞吐量，达到了500 tokens/s。优化了模型的推理速度和资源利用率，确保了高并发场景下的稳定性。
- 使用Tornado服务将模型docker化部以Restful API形式部署到线上服务器，并使用OpenTelemetry埋点进行链路追中。

### 问答Agent系统（从0到1）

- 基于RAG（检索增强生成）架构开发智能问答agent，并成功集成了ElasticSearch中的Title/Subtitle/Content多域的全索引召回和排序，同时排序中加入可学习权重的语义相似度模型。
- 运用Scikit-learn库中的TF-IDF算法与Embedding减速和SimCSE算法优化了多路召回机制，显著提升问答精度与响应速度。确保了对复杂查询的即时响应和高度相关答案的精准检索。
- 提取用户query、doc、topic等特征训练LightGBM模型提高排序合理性。

### 系统架构设计

- 设计并实现了全面的智能面试系统架构，涵盖面试题生成、考核维度定义和综合评估等功能，支持个性化面试问题、自动追问与评分机制，提升线上面试的智能化和互动体验。
- 构建了基于业务需求的大模型测试和评估系统，实现了快速切换基座模型的pipeline，确保了面试测评的准确度和行业领先性。通过持续的模型评估和优化，保持了技术解决方案的竞争力。

---

目的涌现(中国，北京)
AI技术负责人
2023-07 ~ 2024-02
业务方向：AI+教育，通过3D虚拟世界的场景对话，结合社交与游戏玩法让用户练习口语。

### Multi-Agents对话引擎（从0到1）

- 基于In-Context-Learning（ICL）开发了[Stanford Village AGI](https://arxiv.org/abs/2304.03442)（斯坦福小镇）项目，负责从技术设计到项目部署的全生命周期，通过集成LangChain和Pinecone向量数据库，以及MySQL数据库，构建了RAG架构，显著提升了agent的长短期记忆和决策能力。
- 独立开发automatic agents与generative agent框架，实现了multi-agent之间以及用户与agent自然对话的CoT能力，显著提升了用户体验。
- 开发了一套高效的对话 data processing pipeline，引入了先进的文本处理技术，实现了数据的semi-auto labeling，提升了数据的准确性和可用性。制定了详细的数据标注规范，确保了标注的一致性和高准确率，为模型训练提供了可靠的数据基础。
- 主导了ASR和TTS技术的集成，以及Whisper和DALLE-3模型的引入，构建agent聊天内容多样性，同时确保成本效益。
- 设计并实施了基于few-shot learning与prompt engineering的agent背景信息设定，通过GPT模型对千条对话语料进行distillation和SFT，精确控制agent情感表达，增强了交互的真实感。

### 模型训练

- 训练并优化了BERT、NLU完成sentiment analysis和intent recognition，采用P-tuning和LoRA微调技术，提高了模型的响应质量和准确性。
- 构建并验证了经济数学模型，准确预测了token成本、日活跃用户(DAU)与收益平衡点，为制定最优算法策略提供了数据支持，成功减少了运营成本。

离职原因：公司发展方向不需要算法部门

---

加州大学洛杉矶分校(美国，洛杉矶)
客座讲师
2021-07 ~ 2023-07

- 教授融合理论与实践的自然语言处理硕士课程，内容包括但不限于Seq2Seq、RNN、LSTM、Transformer、BERT、GPT。
- 指导300多名研究生在顶级期刊上发表论文及国际会议上发表演讲，引导学生开展诸多大语言模型(LLM)项目解决AI领域理论和实践挑战。
- 与行业紧密合作应用LLM将学术研究转化为解决方案，积极参与学术与行业领域研讨并贡献对新兴技术的见解。

---

诺斯罗普格鲁曼(美国，洛杉矶)
算法专家
2016-08 ~ 2023-07

### 公司介绍

诺思罗普·格鲁曼公司是世界第三大军工生产厂商，一家高科技公司，组建于1994年，2024年财富世界500强排行榜排名第109名。

### 工作职责

- 大模型训练与开发：负责利用BERT、GPT、T5等前沿大型预训练模型，开发智能对话系统，实现深层次的自然语言理解、生成和对话管理，显著提升用户体验。
- NLP算法研发领导：主导NLP算法的研发和优化工作，融合深度学习技术（RNN、CNN、LSTM、GRU）和机器学习算法（强化学习RL、决策树DT、SGD、XGBoost等），构建复杂的预测模型，提高推荐系统的准确率。
- 团队管理与敏捷开发：领导算法团队采用敏捷开发模式，快速迭代推荐和预测分析工具。全面管理项目生命周期，采用DevOps实践，促进跨部门协作，确保项目按时按预算交付。

#### 模型构建与优化

- 语义理解与响应生成：利用BERT和T5模型进行深入的语义理解，有效解析用户输入命令，生成精准响应。
- 交互自然度提升：参考LaMDA框架，结合GPT-Neo模型，根据历史交互生成回复，提升了交互的自然度和准确性。
- 智能化对话系统：运用BERT、GPT等NLP模型，对用户输入的指令进行语义理解，实现了对话系统的智能化，提升了用户体验。
- 深度学习框架应用：运用PyTorch框架，成功实现了RNN、LSTM等深度学习模型，增强了模型的泛化能力，确保了模型在不同周期数据集上的稳定性和可靠性。
- 机器学习模型开发：设计并实施SGD、随机森林、K-Means等模型，对数据特征进行深入分类与筛选，显著提升了训练数据的质量。
- 预测精度提升：构建并训练基于supervised learning的模型，通过创新的数据特征组合方法，实现了85%的平均准确率，显著提高了多船位置的预测精度。
- DevOps流水线构建：构建了一个健壮的DevOps流水线，采用Docker容器技术确保开发和生产环境间的一致性构建。
- 代码质量管理：集成了Jenkins进行持续集成，SonarQube进行代码质量分析，以及GCov进行代码覆盖率分析，确保开发过程中维持高标准的代码质量。

---

- 语音识别技术：运用SpeechBrain框架，识别录音中说话人，完成语音识别、合成、区分、识别、验证，实现95%的召回率和0.9的AUC。
- 弱监督学习方案：提出弱监督co-training方案，以5分钟录音片段为单位进行检测，有效减少正样本噪声，增强模型鲁棒性。
- 特征工程与模型训练：构建n-gram特征，进行特征聚类及场景拆分，使用PMI-n-gram和SimCSE encoder，解决稀疏特征正样本召回问题。
- 模型集成与优化：结合CNN深度模型与n-gram线性模型，实现模型快速上线和高准确率。
- 图像与文本分析：应用Faster R-CNN和Detectron等先进的对象检测算法，结合Visual BERT、ViLBERT、RoBERT、BiLSTM等深度学习模型，实现了对图像和文本内容的多分类意图识别。这些技术的应用显著提升了系统对图像和文本中潜在冒犯性内容的识别精度。
- 深度学习模型搭建：使用Tensorflow框架构建了VGG、ResNet、Mobilenet等深度学习分类网络，并通过Adam优化器进行模型训练。通过严格的模型选择流程，确保了只有高准确率的模型被部署到生产环境中，从而保证了系统的高效性和可靠性。
- 模型融合策略：为了进一步提升检测性能，实施了soft/hard learning方法，整合了不同模型的检测结果。利用PyTorch和Scikit-learn框架，设计了一套模型融合策略，通过综合各个模型的优势，输出了最优的检测结果。
- DevOps实践：构建了一个健壮的DevOps流水线，采用Docker容器技术确保开发和生产环境间的一致性构建。集成了Jenkins进行持续集成，SonarQube进行代码质量分析，以及GCov进行代码覆盖率分析，确保开发过程中维持高标准的代码质量。

---
