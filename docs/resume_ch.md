# 简历

## 教育背景

佐治亚理工学院(美国，佐治亚)
计算机科学(硕士)
2014-09 ~ 2016-06

加州大学洛杉矶分校(美国，洛杉矶)
数学(学士)
2010-09 ~ 2014-06

## 工作经验

---
海纳AI(中国，北京)
NLP算法负责人
2024-03 ~ 至今
离职原因：公司资金链断裂，无法支付员工薪资

### 模型训练

- 跟随[InstructGPT](https://arxiv.org/abs/2203.02155)论文中数据类别、数量、长度分布利用私有数据源、Python爬虫技术，self-instruct方式，成功构建了高效、自动化的训练和测试数据pipeline生成了万条SFT数据。
- 采用LoRA和QLoRA技术对ChatGLM3/4、LLaMA2/3、Qwen、InternLM等不同规模（6B-32B参数）的开源大模型进行监督微调（SFT），确保模型输出的稳定性与一致性。
- 通过PPO、DPO和RLHF等先进算法对模型输出进行了细致的对齐和优化，以适应面试领域的特定需求，实现了模型在面试领域的SOTA（State of the Art）性能。
- 利用Embedding对比相关性改进了few-shot学习方式提升了小样本学习场景下的模型性能，结合COT方法提出causal inference策略增强了模型对复杂问题解决的推理能力。
- 通过对比四种不同的模型优化方案，进行了细致的微调实验，最终实现了模型准确率的显著提升
- 应用FastLLM、vLLM、llama.cpp、TensorRT等模型推理加速框架，结合Triton服务部署，显著提高了模型的吞吐量，达到了500 tokens/s。优化了模型的推理速度和资源利用率，确保了高并发场景下的稳定性。
- 使用Tornado服务将模型docker化部以Restful API形式部署到线上服务器，并使用OpenTelemetry埋点进行链路追中。

### 问答系统开发（从0到1）

- 基于RAG（检索增强生成）架构开发智能QA-Bot（问答机器人），并成功集成了ElasticSearch中的Title/Subtitle/Content多域的全索引召回和排序，同时排序中加入可学习权重的语义相似度模型。
- 运用Scikit-learn库中的TF-IDF算法与Embedding减速和SimCSE算法优化了多路召回机制，显著提升问答精度与响应速度。确保了对复杂查询的即时响应和高度相关答案的精准检索。
- 提取用户query、doc、topic等特征训练LightGBM模型提高排序合理性。

### 系统架构设计

- 设计并实现了全面的智能面试系统架构，涵盖面试题生成、考核维度定义和综合评估等功能，支持个性化面试问题、自动追问与评分机制，提升线上面试的智能化和互动体验。
- 构建了基于业务需求的大模型测试和评估系统，实现了快速切换基座模型的pipeline，确保了面试测评的准确度和行业领先性。通过持续的模型评估和优化，保持了技术解决方案的竞争力。

---

目的涌现(中国，北京)
AI技术负责人
2023-07 ~ 2024-02
离职原因：公司发展方向不需要算法部门

### 多智能体对话引擎（从0到1）

- 基于In-Context-Learning（ICL）开发了[Stanford Village AGI](https://arxiv.org/abs/2304.03442)项目，负责从技术设计到项目部署的全生命周期，通过集成LangChain和Pinecone向量数据库，以及MySQL数据库，构建了RAG架构，显著提升了智能体的长短期记忆和决策能力。
- 独立开发了人机对话流程，实现了多智能体之间以及用户与智能体自然对话的CoT能力，显著提升了用户体验。
- 开发了一套高效的dialog data processing pipeline，引入了先进的文本处理技术，实现了数据的semi-auto labeling，提升了数据的准确性和可用性。制定了详细的数据标注规范，确保了标注的一致性和高准确率，为模型训练提供了可靠的数据基础。
- 主导了ASR和TTS技术的集成，以及Whisper和DALLE-3模型的引入，为用户提供了无缝的语音交互体验，显著提升了对话的自然度和用户满意度，同时确保成本效益。
- 设计并实施了基于few-shot learning与prompt engineering的虚拟人物背景信息设定，通过GPT模型对千条对话语料进行distillation和SFT，精确控制人物情感表达，增强了交互的真实感。

### 模型训练

- 训练并优化了BERT、NLU完成sentiment analysis和intent recognition，采用P-tuning和LoRA微调技术，提高了模型的响应质量和准确性。
- 构建并验证了经济数学模型，准确预测了token成本、日活跃用户(DAU)与收益平衡点，为制定最优算法策略提供了数据支持，成功减少了运营成本。

---

加州大学洛杉矶分校(美国，洛杉矶)
客座教授
2021-07 ~ 2023-07

- 教授融合理论与实践的自然语言处理(NLP)硕士课程，内容包括但不限于Seq2Seq、RNN、LSTM、Transformer、BERT、GPT。
- 指导300多名研究生在顶级期刊上发表论文及国际会议上发表演讲，引导学生开展诸多大语言模型(LLM)项目解决AI领域理论和实践挑战。
- 与行业紧密合作应用LLM将学术研究转化为解决方案，积极参与学术与行业领域研讨并贡献对新兴技术的见解。

---

诺斯罗普格鲁曼(美国，洛杉矶)
算法专家
2016-08 ~ 2023-07

### 工作职责

- 领导算法研发：主导指挥控制平台的算法优化，融合机器学习（包括强化学习RL、决策树DT、随机梯度下降SGD、XGBoost等）和深度学习技术（如RNN、CNN、LSTM、GRU），构建复杂预测模型，显著提升推荐系统的准确率。
- 团队管理与敏捷开发：引领算法团队采用敏捷开发模式，快速迭代推荐和预测分析工具。全面管理项目生命周期，采用DevOps实践，促进跨部门协作，确保项目按时按预算交付。

### 项目介绍

多船位置预测模型
业务owner
2022-01 ~ 2023-07

#### 项目概述

作为业务Owner，负责领导一个跨学科团队，开发一个创新的多船位置预测模型。该项目旨在通过高级数据分析和机器学习技术，精确预测海上船只的位置。

#### 模型构建与优化

- 机器学习模型开发：设计并实施SGD、随机森林、K-Means等模型，对数据特征进行深入分类与筛选，显著提升了训练数据的质量。
- 预测精度提升：构建并训练基于supervised learning的模型，通过创新的数据特征组合方法，实现了85%的平均准确率，显著提高了多船位置的预测精度。
- 深度学习框架应用：运用PyTorch框架，成功实现了RNN、LSTM等深度学习模型，增强了模型的泛化能力，确保了模型在不同周期（日、月、年）数据集上的稳定性和可靠性。
- 自然语言处理应用：利用BERT和T5模型进行深入的语义理解，有效解析用户输入命令，生成精准响应。参考LaMDA框架，结合GPT-Neo模型，根据历史交互生成回复，提升了交互的自然度和准确性。

#### 团队协调与管理

- 敏捷团队管理：负责三个敏捷团队的协调与管理，运用MLFlow平台，优化模型生命周期管理，显著提升了团队工作效率和协作能力。
- 跨领域系统集成：设计并实现了一个高度集成的控制站，支持多领域的无人系统，包括航空、水面、水下和地面平台，实现了跨平台的数据处理和命令控制，为海上交通管理提供了强有力的技术支持。

#### 成果与影响

- 业务影响：通过精确的位置预测，为海上交通管理提供了数据支持，显著提高了海上交通安全和效率。
- 技术创新：该项目的成功实施，展示了在复杂环境下应用机器学习和自然语言处理技术的可能性，为未来相关技术的应用提供了宝贵经验。

---

NLP对录音进行转录和语音识别
算法专家
2021-01 ~ 2022-01

#### 项目概述

负责开发和优化一个高精度的语音识别系统，该系统能够处理和分析大量录音数据，为转录服务提供技术支持。项目的目标是通过先进的NLP技术和机器学习模型，提高语音到文本转换的准确性和效率。

#### 技术成就

- 语音识别技术：

  - 框架应用：成功运用SpeechBrain框架，实现了对录音中说话人的高精度识别。
  - 流程完善：完成了从语音识别到合成、区分、识别、验证的全流程开发，确保了系统的端到端性能。
  - 性能指标：通过优化模型参数和训练策略，实现了95%的召回率和0.9的AUC，显著提升了系统的整体性能。

- 弱监督学习方案：

  - 创新方法：提出了一种创新的弱监督co-training方案，该方案通过利用未标记数据增强模型的学习能力。
  - 数据策略：以5分钟录音片段为单位进行检测，有效地筛选和利用了高质量的正样本，减少了噪声数据的影响。
  - 模型鲁棒性：增强了模型对不同录音环境和说话人变化的适应能力，提高了系统的鲁棒性。
  
- 特征工程与模型训练：

  - 特征构建：构建了有效的n-gram特征，并进行了深入的特征聚类及场景拆分，以提取最有价值的信息。
  - 编码技术：应用PMI-n-gram和SimCSE encoder技术，解决了稀疏特征正样本的召回问题，提升了特征的表达能力。
  - 模型训练：通过精心设计的训练流程和参数调优，确保了模型在各种数据集上都能达到最优性能。

- 模型集成与优化：

  - 深度学习应用：结合了CNN深度模型与n-gram线性模型，利用各自的优势提升了识别的准确率。
  - 快速迭代：实现了模型的快速上线，通过持续的优化和测试，确保了模型在生产环境中的稳定性和高效性。
  - 性能提升：通过模型融合策略，实现了高准确率的目标，为语音识别服务提供了强有力的技术支持。

---

结合NLP和CV检测冒犯性内容
算法工程师
2018-04 ~ 2020-12

### 项目概述

作为项目核心成员，负责开发和优化一个集成自然语言处理（NLP）和计算机视觉（CV）技术的系统，用于自动检测和识别网络内容中的冒犯性内容。该项目旨在提高在线平台的内容安全性，保护用户免受有害信息的影响。

### 技术成就

- 图像与文本分析：

  - 对象检测算法：应用Faster R-CNN和Detectron等先进的对象检测算法，精确识别图像中的关键元素。
  - 深度学习模型：结合Visual BERT、ViLBERT、RoBERTa、BiLSTM等深度学习模型，实现了对图像和文本内容的多分类意图识别，显著提升了系统对潜在冒犯性内容的识别精度。

- 深度学习模型搭建：

  - 框架应用：使用Tensorflow框架构建了VGG、ResNet、Mobilenet等深度学习分类网络，有效处理大规模图像和文本数据。
  - 模型训练与优化：通过Adam优化器进行模型训练，并通过严格的模型选择流程，确保只有高准确率的模型被部署到生产环境中，保证了系统的高效性和可靠性。

-模型融合策略：

  - 性能提升：实施了soft/hard learning方法，整合了不同模型的检测结果，进一步提升了检测性能。
  - 框架利用：利用PyTorch和Scikit-learn框架，设计了一套模型融合策略，通过综合各个模型的优势，输出了最优的检测结果。

- DevOps实践：

  - 持续集成与部署：构建了一个健壮的DevOps流水线，采用Docker容器技术确保开发和生产环境间的一致性构建。
  - 代码质量管理：集成了Jenkins进行持续集成，SonarQube进行代码质量分析，以及GCov进行代码覆盖率分析，确保开发过程中维持高标准的代码质量。

---
